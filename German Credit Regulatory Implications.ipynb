{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da5bac5-5632-4c70-9d4f-bac85d25b49c",
   "metadata": {},
   "source": [
    "# German Credit Regulatory Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1103620-c751-4216-b5c8-2c04d06a4495",
   "metadata": {},
   "source": [
    "This project implemented a Basel III-compliant Internal Ratings-Based (IRB) credit risk system to assess capital requirements for a loan portfolio. The model calculates Probability of Default (PD), Risk-Weighted Assets (RWA), and regulatory capital while incorporating stress testing to evaluate resilience under adverse economic conditions.\n",
    "\n",
    "This project  developed a comprehensive, Basel III-compliant credit risk framework that transforms raw loan data into actionable regulatory capital insights. By integrating machine learning with financial risk modeling, the system provides banks with a powerful tool for default prediction, capital adequacy assessment, and stress testing.\n",
    "\n",
    "#### Strategic Value\n",
    "\n",
    "This system enables banks to:\n",
    "\n",
    "- Proactively manage risk through PD monitoring\n",
    "- Optimize capital allocation per Basel requirements\n",
    "- Demonstrate regulatory compliance with auditable calculations\n",
    "\n",
    "While the framework provides a robust foundation for internal ratings-based approaches, its true value will emerge through iterative refinement using real-world portfolio data. The project demonstrates how machine learning and regulatory finance can converge to create smarter risk management systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ee93a8-1536-4cbb-9266-7e6aad7e9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IRB Credit Risk System - Basel III Compliant Capital Calculator\n",
    "\n",
    "This system calculates regulatory capital requirements using the Internal Ratings-Based (IRB) approach\n",
    "with the following components:\n",
    "1. Data preprocessing and feature engineering\n",
    "2. Probability of Default (PD) modeling\n",
    "3. Risk Weighted Assets (RWA) calculation\n",
    "4. Stress testing capabilities\n",
    "5. Reporting and analysis tools\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f80bf-97fd-4cd7-99ae-bb02554e8ce3",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing\n",
    "\n",
    "Loads raw credit data, cleans it, and engineers financial risk features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0138b392-642c-4432-ad8a-9546f2526689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditDataPreprocessor:\n",
    "    \"\"\"Handles all data loading and preprocessing operations\"\"\"\n",
    "    \n",
    "    DEFAULT_COLUMN_MAPPING = {\n",
    "        'laufkont': 'Status',\n",
    "        'laufzeit': 'Duration',\n",
    "        'moral': 'CreditHistory',\n",
    "        'verw': 'Purpose',\n",
    "        'hoehe': 'Amount',\n",
    "        'sparkont': 'Savings',\n",
    "        'beszeit': 'EmploymentDuration',\n",
    "        'rate': 'InstallmentRate',\n",
    "        'famges': 'PersonalStatus',\n",
    "        'buerge': 'OtherDebtors',\n",
    "        'wohnzeit': 'ResidenceDuration',\n",
    "        'verm': 'Property',\n",
    "        'alter': 'Age',\n",
    "        'weitkred': 'OtherInstallments',\n",
    "        'wohn': 'Housing',\n",
    "        'bishkred': 'NumCredits',\n",
    "        'beruf': 'Job',\n",
    "        'pers': 'Dependents',\n",
    "        'telef': 'Telephone',\n",
    "        'gastarb': 'ForeignWorker',\n",
    "        'kredit': 'Default'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, column_mapping=None, min_bin_size=50):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            column_mapping: Dictionary for renaming columns\n",
    "            min_bin_size: Minimum samples per bin for numerical features\n",
    "        \"\"\"\n",
    "        self.column_mapping = column_mapping or self.DEFAULT_COLUMN_MAPPING\n",
    "        self.min_bin_size = min_bin_size\n",
    "        self.feature_stats_ = {}\n",
    "        \n",
    "    def load_data(self, filepath):\n",
    "        \"\"\"Load and validate credit data\"\"\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Rename columns using mapping\n",
    "        df = df.rename(columns={k: v for k, v in self.column_mapping.items() \n",
    "                               if k in df.columns})\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_columns = ['Duration', 'Amount', 'Age', 'Default']\n",
    "        missing = [col for col in required_columns if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Clean and transform raw data\"\"\"\n",
    "        # Convert target: 1=default, 0=non-default\n",
    "        if df['Default'].max() == 2:  # German credit data format\n",
    "            df['Default'] = df['Default'] - 1\n",
    "            \n",
    "        # Handle missing values\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Add financial ratios\n",
    "        df = self._add_financial_features(df)\n",
    "        \n",
    "        # Store feature statistics\n",
    "        self._store_feature_stats(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_financial_features(self, df):\n",
    "        \"\"\"Create financial ratios and risk indicators\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Liquidity ratios\n",
    "        df['DebtToIncome'] = df['Amount'] / (df['Duration'] + 1e-6)\n",
    "        df['InstallmentBurden'] = df['InstallmentRate'] / (df['Amount'] + 1e-6)\n",
    "        \n",
    "        # Stability indicators\n",
    "        df['AgeSquared'] = df['Age'] ** 2\n",
    "        df['LogAmount'] = np.log(df['Amount'] + 1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _store_feature_stats(self, df):\n",
    "        \"\"\"Store descriptive statistics for features\"\"\"\n",
    "        self.feature_stats_ = {\n",
    "            'mean': df.mean(),\n",
    "            'std': df.std(),\n",
    "            'min': df.min(),\n",
    "            'max': df.max()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa2805-de63-4c76-94dd-477580318583",
   "metadata": {},
   "source": [
    "## Weight of Evidence (WoE) Transformation\n",
    "\n",
    "Transforms categorical/numerical features into WoE values for better model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06786b80-3407-491b-93a6-b595fbdd4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoETransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Weight of Evidence transformation for credit risk features\"\"\"\n",
    "    \n",
    "    def __init__(self, n_bins=5, min_bin_size=50, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_bins: Number of bins for numerical features\n",
    "            min_bin_size: Minimum samples per bin\n",
    "            epsilon: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        self.n_bins = n_bins\n",
    "        self.min_bin_size = min_bin_size\n",
    "        self.epsilon = epsilon\n",
    "        self.bin_edges_ = {}\n",
    "        self.woe_dict_ = {}\n",
    "        self.iv_dict_ = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Calculate WoE and IV for all features\"\"\"\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        y = pd.Series(y).copy()\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if pd.api.types.is_numeric_dtype(X[col]):\n",
    "                self._fit_numeric(X[col], y, col)\n",
    "            else:\n",
    "                self._fit_categorical(X[col], y, col)\n",
    "                \n",
    "            self._check_monotonicity(col)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform features to WoE values\"\"\"\n",
    "        if not hasattr(self, 'woe_dict_'):\n",
    "            raise NotFittedError(\"Transformer not fitted yet\")\n",
    "            \n",
    "        X = pd.DataFrame(X).copy()\n",
    "        X_woe = pd.DataFrame(index=X.index)\n",
    "        \n",
    "        for col in self.woe_dict_:\n",
    "            if col not in X.columns:\n",
    "                raise ValueError(f\"Feature {col} missing in transform data\")\n",
    "                \n",
    "            if col in self.bin_edges_:\n",
    "                binned = pd.cut(X[col], bins=self.bin_edges_[col], include_lowest=True)\n",
    "                X_woe[col] = binned.astype(str).map(self.woe_dict_[col]['woe'])\n",
    "            else:\n",
    "                X_woe[col] = X[col].astype(str).map(self.woe_dict_[col]['woe'])\n",
    "                \n",
    "            # Handle unseen categories/missing\n",
    "            X_woe[col] = X_woe[col].fillna(self.woe_dict_[col]['woe'].mean())\n",
    "            \n",
    "        return X_woe\n",
    "    \n",
    "    def _fit_numeric(self, x, y, col):\n",
    "        \"\"\"Calculate WoE for numeric features\"\"\"\n",
    "        try:\n",
    "            # Try quantile binning first\n",
    "            bins = pd.qcut(x, q=self.n_bins, duplicates='drop', retbins=True)[1]\n",
    "            \n",
    "            # Check bin sizes\n",
    "            bin_counts = pd.cut(x, bins=bins).value_counts()\n",
    "            if any(bin_counts < self.min_bin_size):\n",
    "                bins = np.histogram_bin_edges(x, bins='doane')\n",
    "                \n",
    "            self.bin_edges_[col] = bins\n",
    "            binned = pd.cut(x, bins=bins, include_lowest=True)\n",
    "            crosstab, iv = self._calculate_woe(binned.astype(str), y)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not bin {col} with quantiles: {str(e)}\")\n",
    "            # Fall back to equal-width bins\n",
    "            bins = np.linspace(x.min(), x.max(), self.n_bins + 1)\n",
    "            self.bin_edges_[col] = bins\n",
    "            binned = pd.cut(x, bins=bins, include_lowest=True)\n",
    "            crosstab, iv = self._calculate_woe(binned.astype(str), y)\n",
    "            \n",
    "        self.woe_dict_[col] = crosstab\n",
    "        self.iv_dict_[col] = iv\n",
    "        \n",
    "    def _fit_categorical(self, x, y, col):\n",
    "        \"\"\"Calculate WoE for categorical features\"\"\"\n",
    "        crosstab, iv = self._calculate_woe(x.astype(str), y)\n",
    "        self.woe_dict_[col] = crosstab\n",
    "        self.iv_dict_[col] = iv\n",
    "        \n",
    "    def _calculate_woe(self, x, y):\n",
    "        \"\"\"Calculate Weight of Evidence and Information Value\"\"\"\n",
    "        crosstab = pd.crosstab(x, y, margins=False)\n",
    "        \n",
    "        # Ensure both classes exist\n",
    "        if len(crosstab.columns) < 2:\n",
    "            missing_class = 1 if 0 in crosstab.columns else 0\n",
    "            crosstab[missing_class] = self.epsilon\n",
    "            \n",
    "        crosstab.columns = ['good', 'bad']\n",
    "        crosstab['total'] = crosstab['good'] + crosstab['bad']\n",
    "        \n",
    "        # Stable WoE calculation\n",
    "        crosstab['p_good'] = (crosstab['good'] + 0.5) / (crosstab['good'].sum() + 0.5)\n",
    "        crosstab['p_bad'] = (crosstab['bad'] + 0.5) / (crosstab['bad'].sum() + 0.5)\n",
    "        crosstab['woe'] = np.log(crosstab['p_good'] / crosstab['p_bad'])\n",
    "        crosstab['iv'] = (crosstab['p_good'] - crosstab['p_bad']) * crosstab['woe']\n",
    "        \n",
    "        return crosstab.sort_values('woe'), crosstab['iv'].sum()\n",
    "    \n",
    "    def _check_monotonicity(self, col):\n",
    "        \"\"\"Check for monotonic WoE patterns\"\"\"\n",
    "        woe = self.woe_dict_[col]['woe']\n",
    "        if not (woe.is_monotonic_increasing or woe.is_monotonic_decreasing):\n",
    "            print(f\"Warning: Non-monotonic WoE for {col} - consider manual binning\")\n",
    "            \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Return feature importance based on Information Value\"\"\"\n",
    "        iv_df = pd.DataFrame({\n",
    "            'Feature': list(self.iv_dict_.keys()),\n",
    "            'IV': list(self.iv_dict_.values())\n",
    "        }).sort_values('IV', ascending=False)\n",
    "        \n",
    "        iv_df['Strength'] = pd.cut(\n",
    "            iv_df['IV'],\n",
    "            bins=[-np.inf, 0.02, 0.1, 0.3, np.inf],\n",
    "            labels=['Unpredictive', 'Weak', 'Medium', 'Strong']\n",
    "        )\n",
    "        return iv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e841252-6587-4ffa-b552-e1eb87d5ccfc",
   "metadata": {},
   "source": [
    "## Probability of Default (PD) Modeling \n",
    "\n",
    "Trains a machine learning model to predict the likelihood of default.\n",
    "\n",
    "This also includes:\n",
    "\n",
    "- Capital Calculation (Basel III Formula): Computes Risk-Weighted Assets (RWA) and Regulatory Capital using Basel III rules.\n",
    "- Stress Testing: Simulates how capital requirements change under economic stress (e.g., recession).\n",
    "- - Portfolio Analysis & Reporting: Generates risk insights and regulatory reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baaad1a2-c262-4024-9f96-a0167e57bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRBCreditModel:\n",
    "    \"\"\"Basel III IRB Approach Credit Risk Model\"\"\"\n",
    "    \n",
    "    def __init__(self, lgd=0.45, confidence=0.999, maturity=2.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lgd: Loss Given Default (45%)\n",
    "            confidence: Confidence level (99.9% for Basel III)\n",
    "            maturity: Effective maturity in years\n",
    "        \"\"\"\n",
    "        self.lgd = lgd\n",
    "        self.confidence = confidence\n",
    "        self.maturity = maturity\n",
    "        self.pd_model = None\n",
    "        self.preprocessor = CreditDataPreprocessor()\n",
    "        self.woe_transformer = None\n",
    "        \n",
    "    def load_and_preprocess(self, filepath):\n",
    "        \"\"\"Load and preprocess credit data\"\"\"\n",
    "        df = self.preprocessor.load_data(filepath)\n",
    "        df = self.preprocessor.preprocess_data(df)\n",
    "        return df\n",
    "    \n",
    "    def train_pd_model(self, X, y):\n",
    "        \"\"\"Train Probability of Default model\"\"\"\n",
    "        sample_weights = compute_sample_weight('balanced', y)\n",
    "        \n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', GradientBoostingClassifier(\n",
    "                n_estimators=150,\n",
    "                max_depth=3,\n",
    "                min_samples_leaf=50,\n",
    "                subsample=0.8,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        model.fit(X, y, classifier__sample_weight=sample_weights)\n",
    "        return model\n",
    "    \n",
    "    def calculate_capital(self, df, exposure_col='Amount'):\n",
    "        \"\"\"Calculate capital requirements for portfolio\"\"\"\n",
    "        # Select features\n",
    "        features = ['Amount', 'Duration', 'Age', 'DebtToIncome', 'InstallmentBurden']\n",
    "        features = [f for f in features if f in df.columns]\n",
    "        \n",
    "        X = df[features]\n",
    "        y = df['Default']\n",
    "        \n",
    "        # Train model if not already trained\n",
    "        if self.pd_model is None:\n",
    "            print(\"Training PD model...\")\n",
    "            self.pd_model = self.train_pd_model(X, y)\n",
    "            \n",
    "        # Predict PDs\n",
    "        df['PD'] = self.pd_model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Calculate capital requirements\n",
    "        df['RWA'] = df.apply(lambda row: self._calculate_rwa(row['PD'], row[exposure_col]), axis=1)\n",
    "        df['Capital'] = df['RWA'] * 0.08  # 8% of RWA\n",
    "        \n",
    "        # Portfolio summary\n",
    "        summary = {\n",
    "            'TotalExposure': df[exposure_col].sum(),\n",
    "            'AvgPD': (df['PD'] * df[exposure_col]).sum() / df[exposure_col].sum(),\n",
    "            'TotalRWA': df['RWA'].sum(),\n",
    "            'TotalCapital': df['Capital'].sum(),\n",
    "            'CapitalRatio': df['Capital'].sum() / df[exposure_col].sum(),\n",
    "            'ModelAUC': roc_auc_score(y, df['PD'])\n",
    "        }\n",
    "        \n",
    "        return df, summary\n",
    "    \n",
    "    def _calculate_rwa(self, pd, ead):\n",
    "        \"\"\"Calculate Risk Weighted Assets per Basel III formula\"\"\"\n",
    "        # Ensure PD is within reasonable bounds\n",
    "        pd = np.clip(pd, 0.0001, 0.9999)\n",
    "        \n",
    "        # Correlation factor\n",
    "        r = (0.12 * (1 - np.exp(-50 * pd)) / (1 - np.exp(-50))) + \\\n",
    "            (0.24 * (1 - (1 - np.exp(-50 * pd)) / (1 - np.exp(-50))))\n",
    "        \n",
    "        # Maturity adjustment\n",
    "        b = (0.11852 - 0.05478 * np.log(pd)) ** 2\n",
    "        maturity_adj = (1 + (self.maturity - 2.5) * b) / (1 - 1.5 * b)\n",
    "        \n",
    "        # Capital requirement\n",
    "        capital = (self.lgd * norm.cdf(\n",
    "            (norm.ppf(pd) + np.sqrt(r) * norm.ppf(self.confidence)) / np.sqrt(1 - r)\n",
    "        ) - pd * self.lgd) * 1.06 * maturity_adj\n",
    "        \n",
    "        # Convert to RWA\n",
    "        rwa = capital * ead * 12.5\n",
    "        return rwa\n",
    "    \n",
    "    def stress_test(self, df, scenario_params):\n",
    "        \"\"\"Apply stress scenario to portfolio\"\"\"\n",
    "        stressed_df = df.copy()\n",
    "        \n",
    "        # Apply PD shock\n",
    "        if 'pd_shock' in scenario_params:\n",
    "            stressed_df['PD'] *= scenario_params['pd_shock']\n",
    "            stressed_df['PD'] = np.clip(stressed_df['PD'], 0, 1)\n",
    "            \n",
    "        # Apply LGD shock\n",
    "        stressed_lgd = min(1.0, self.lgd * scenario_params.get('lgd_shock', 1.0))\n",
    "        \n",
    "        # Apply EAD shock if specified\n",
    "        exposure_col = 'Amount'\n",
    "        if 'ead_shock' in scenario_params:\n",
    "            stressed_df[exposure_col] *= scenario_params['ead_shock']\n",
    "            \n",
    "        # Store original LGD\n",
    "        original_lgd = self.lgd\n",
    "        self.lgd = stressed_lgd\n",
    "        \n",
    "        # Recalculate capital\n",
    "        stressed_df['RWA'] = stressed_df.apply(\n",
    "            lambda row: self._calculate_rwa(row['PD'], row[exposure_col]), axis=1\n",
    "        )\n",
    "        stressed_df['Capital'] = stressed_df['RWA'] * 0.08\n",
    "        \n",
    "        # Reset LGD\n",
    "        self.lgd = original_lgd\n",
    "        \n",
    "        # Stressed summary\n",
    "        summary = {\n",
    "            'TotalExposure': stressed_df[exposure_col].sum(),\n",
    "            'AvgPD': (stressed_df['PD'] * stressed_df[exposure_col]).sum() / \n",
    "                    stressed_df[exposure_col].sum(),\n",
    "            'TotalRWA': stressed_df['RWA'].sum(),\n",
    "            'TotalCapital': stressed_df['Capital'].sum(),\n",
    "            'CapitalRatio': stressed_df['Capital'].sum() / stressed_df[exposure_col].sum(),\n",
    "            'StressedLGD': stressed_lgd\n",
    "        }\n",
    "        \n",
    "        return stressed_df, summary\n",
    "    \n",
    "    def analyze_portfolio(self, df):\n",
    "        \"\"\"Generate portfolio analysis reports\"\"\"\n",
    "        reports = {}\n",
    "        \n",
    "        # Risk grade distribution\n",
    "        df['RiskGrade'] = pd.qcut(\n",
    "            df['PD'], \n",
    "            q=5, \n",
    "            labels=['A (Lowest)', 'B', 'C', 'D', 'E (Highest)']\n",
    "        )\n",
    "        reports['RiskGrades'] = df['RiskGrade'].value_counts().sort_index()\n",
    "        \n",
    "        # Top risky exposures\n",
    "        reports['TopRisky'] = df.nlargest(5, 'PD')[\n",
    "            ['Duration', 'Amount', 'Age', 'PD', 'Capital']\n",
    "        ]\n",
    "        \n",
    "        return reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6067ca1-6d46-4176-b0b1-bd4e8d1521d8",
   "metadata": {},
   "source": [
    "- Risk Grading: Loans are bucketed into A (safest) to E (riskiest).\n",
    "- Top Risky Loans: Identifies high-PD exposures needing attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1a4ec-5afe-4d3c-8b8a-88b9e4db446b",
   "metadata": {},
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1f1a00-9d25-4322-9005-099ebcaf4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded with 1000 records. Default rate: 70.00%\n",
      "\n",
      "Calculating baseline capital...\n",
      "Training PD model...\n",
      "\n",
      "=== BASELINE RESULTS ===\n",
      "Total Exposure: €3,271,248.00\n",
      "Average PD: 49.01%\n",
      "Risk-Weighted Assets: €6,759,498.12\n",
      "Required Capital: €540,759.85\n",
      "Capital Ratio: 16.53% (Min 8%)\n",
      "Model AUC: 0.855\n",
      "\n",
      "Running stress tests...\n",
      "\n",
      "Mild Recession Scenario:\n",
      "Capital Increase: +-28.6%\n",
      "New Capital Ratio: 11.80%\n",
      "\n",
      "Severe Crisis Scenario:\n",
      "Capital Increase: +-63.9%\n",
      "New Capital Ratio: 6.63%\n",
      "\n",
      "Generating portfolio reports...\n",
      "\n",
      "Risk Grade Distribution:\n",
      "RiskGrade\n",
      "A (Lowest)     200\n",
      "B              200\n",
      "C              200\n",
      "D              200\n",
      "E (Highest)    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Riskiest Exposures:\n",
      " Duration  Amount  Age       PD   Capital\n",
      "        6    1750   45 0.975950 20.022263\n",
      "        6     753   64 0.972155  9.952769\n",
      "        7    2329   45 0.971672 31.309427\n",
      "        6    1595   51 0.969263 23.234769\n",
      "        6    1898   34 0.967133 29.529686\n",
      "\n",
      "Results saved to 'irb_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        # Initialize the IRB system\n",
    "        irb = IRBCreditModel(\n",
    "            lgd=0.45,\n",
    "            confidence=0.999,\n",
    "            maturity=2.5\n",
    "        )\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        print(\"Loading data...\")\n",
    "        df = irb.load_and_preprocess(\"german_credit_data.csv\")\n",
    "        print(f\"Data loaded with {len(df)} records. Default rate: {df['Default'].mean():.2%}\")\n",
    "        \n",
    "        # Baseline capital calculation\n",
    "        print(\"\\nCalculating baseline capital...\")\n",
    "        portfolio, baseline = irb.calculate_capital(df)\n",
    "        \n",
    "        print(\"\\n=== BASELINE RESULTS ===\")\n",
    "        print(f\"Total Exposure: €{baseline['TotalExposure']:,.2f}\")\n",
    "        print(f\"Average PD: {baseline['AvgPD']:.2%}\")\n",
    "        print(f\"Risk-Weighted Assets: €{baseline['TotalRWA']:,.2f}\")\n",
    "        print(f\"Required Capital: €{baseline['TotalCapital']:,.2f}\")\n",
    "        print(f\"Capital Ratio: {baseline['CapitalRatio']:.2%} (Min 8%)\")\n",
    "        print(f\"Model AUC: {baseline['ModelAUC']:.3f}\")\n",
    "        \n",
    "        # Stress testing\n",
    "        print(\"\\nRunning stress tests...\")\n",
    "        scenarios = {\n",
    "            \"Mild Recession\": {\"pd_shock\": 1.5, \"lgd_shock\": 1.1},\n",
    "            \"Severe Crisis\": {\"pd_shock\": 2.5, \"lgd_shock\": 1.3, \"ead_shock\": 0.9}\n",
    "        }\n",
    "        \n",
    "        for name, params in scenarios.items():\n",
    "            _, stressed = irb.stress_test(portfolio, params)\n",
    "            print(f\"\\n{name} Scenario:\")\n",
    "            print(f\"Capital Increase: +{(stressed['TotalCapital']/baseline['TotalCapital']-1):.1%}\")\n",
    "            print(f\"New Capital Ratio: {stressed['CapitalRatio']:.2%}\")\n",
    "        \n",
    "        # Portfolio analysis\n",
    "        print(\"\\nGenerating portfolio reports...\")\n",
    "        reports = irb.analyze_portfolio(portfolio)\n",
    "        print(\"\\nRisk Grade Distribution:\")\n",
    "        print(reports['RiskGrades'])\n",
    "        print(\"\\nTop 5 Riskiest Exposures:\")\n",
    "        print(reports['TopRisky'].to_string(index=False))\n",
    "        \n",
    "        # Save results\n",
    "        portfolio.to_csv(\"irb_results.csv\", index=False)\n",
    "        print(\"\\nResults saved to 'irb_results.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        print(\"Troubleshooting steps:\")\n",
    "        print(\"1. Verify input file exists and is accessible\")\n",
    "        print(\"2. Check required columns are present\")\n",
    "        print(\"3. Ensure target variable has values 0 (good) and 1 (bad)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfd977-b42c-4e1e-abdd-e5dc921e80f0",
   "metadata": {},
   "source": [
    "### Business Implications\n",
    "\n",
    "**Portfolio Risk**\n",
    "- This appears to be a \"toxic\" portfolio requiring immediate attention\n",
    "- The bank would need to either:\n",
    "- Increase capital reserves significantly\n",
    "- Reduce exposure to high-risk borrowers\n",
    "\n",
    "**Regulatory Concerns**\n",
    "- Baseline capital is adequate (16.53% > 8%)\n",
    "- But severe stress scenario breaches minimum requirements\n",
    "- Would likely fail regulatory stress tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d253b-5944-4c3b-8858-4d994d8a13b6",
   "metadata": {},
   "source": [
    "## Key Achievements\n",
    "\n",
    "- Basel III Compliance: The model follows regulatory guidelines for capital calculation, including correlation and maturity adjustments.\n",
    "- Machine Learning Integration: A Gradient Boosting Classifier (AUC: 0.855) effectively predicts PD, demonstrating strong discriminatory power.\n",
    "- Stress Testing Framework: The system evaluates capital adequacy under different economic scenarios, though results indicated potential methodological refinements.\n",
    "- Risk Segmentation: Loans were categorized into risk grades (A-E), helping identify high-risk exposures.\n",
    "\n",
    "### Findings & Insights\n",
    "\n",
    "- The portfolio exhibited an extremely high default rate (70%), suggesting either a high-risk segment or possible data anomalies.\n",
    "- The baseline capital ratio (16.53%) exceeded the minimum 8% requirement, but stress tests revealed vulnerabilities under severe crises.\n",
    "- Stress Test Anomalies: Capital requirements unexpectedly decreased under stress—likely due to implementation issues that need review.\n",
    "\n",
    "## Recommendations for Improvement\n",
    "\n",
    "- Data Validation: Verify default definitions and ensure realistic risk distributions.\n",
    "- Stress Test Debugging: Fix capital calculation logic to ensure proper sensitivity to PD/LGD shocks.\n",
    "- Model Calibration: Test PD predictions against actual default rates for better reliability.\n",
    "- Regulatory Reporting: Enhance documentation for compliance audits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ddfe0-d612-4da9-86a3-7bd39c021a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ab8f6-c40b-4e4c-a648-186874e1dd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
